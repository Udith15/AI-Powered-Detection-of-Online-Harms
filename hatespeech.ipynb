{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:00:38.658165Z",
     "iopub.status.busy": "2025-03-26T13:00:38.657865Z",
     "iopub.status.idle": "2025-03-26T13:00:39.437607Z",
     "shell.execute_reply": "2025-03-26T13:00:39.436638Z",
     "shell.execute_reply.started": "2025-03-26T13:00:38.658117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Samples: 20148\n",
      "                                                text       label\n",
      "0  i dont think im getting my baby them white 9 h...      normal\n",
      "1  we cannot continue calling ourselves feminists...      normal\n",
      "2                      nawt yall niggers ignoring me      normal\n",
      "3  <user> i am bit confused coz chinese ppl can n...  hatespeech\n",
      "4  this bitch in whataburger eating a burger with...  hatespeech\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load HateXplain JSON dataset\n",
    "with open('/kaggle/input/hatexplain-dataset/HateXplain_dataset.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total Data Samples: {len(data)}\")\n",
    "\n",
    "# Extract post text and labels\n",
    "posts = []\n",
    "labels = []\n",
    "\n",
    "for sample in data.values():\n",
    "    text = sample['post_tokens']  # list of words\n",
    "    joined_text = ' '.join(text)\n",
    "    posts.append(joined_text)\n",
    "    \n",
    "    # Majority vote label (e.g., 'hate', 'offensive', 'normal')\n",
    "    majority_label = sample['annotators'][0]['label']\n",
    "    labels.append(majority_label)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'text': posts, 'label': labels})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:00:41.321010Z",
     "iopub.status.busy": "2025-03-26T13:00:41.320692Z",
     "iopub.status.idle": "2025-03-26T13:00:41.333312Z",
     "shell.execute_reply": "2025-03-26T13:00:41.332549Z",
     "shell.execute_reply.started": "2025-03-26T13:00:41.320984Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "normal        8209\n",
       "hatespeech    5991\n",
       "offensive     5948\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:00:53.511910Z",
     "iopub.status.busy": "2025-03-26T13:00:53.511608Z",
     "iopub.status.idle": "2025-03-26T13:01:15.804289Z",
     "shell.execute_reply": "2025-03-26T13:01:15.803381Z",
     "shell.execute_reply.started": "2025-03-26T13:00:53.511886Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7058b6b6c8f4284b083f4cc248ceef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f1de76cab94c579e2b8840d52088dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cfc9446e0a4010b67803aef7cd71dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce498a07549040cd836ec893908dc75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aed643576544afb30653677c5eed63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16118 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94357b302ea54167bb37bb452ead5fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18fe9cfca3854769a969e0bee002e9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Install required library if not installed\n",
    "# !pip install transformers datasets scikit-learn torch pandas\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# # Load dataset\n",
    "# df = pd.read_csv('your_dataset.csv')  # Replace with your CSV file name\n",
    "# print(df.head())\n",
    "\n",
    "# Encode labels if not already encoded\n",
    "label_mapping = {'hatespeech': 0, 'offensive': 1, 'normal': 2}\n",
    "df['label'] = df['label'].map(label_mapping)\n",
    "\n",
    "# Split into train and validation\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42\n",
    ")\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize data\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=300)\n",
    "\n",
    "# Convert to Hugging Face dataset\n",
    "train_dataset = Dataset.from_dict({'text': train_texts.tolist(), 'label': train_labels.tolist()})\n",
    "val_dataset = Dataset.from_dict({'text': val_texts.tolist(), 'label': val_labels.tolist()})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize, batched=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_dataset = train_dataset.remove_columns(['text'])\n",
    "val_dataset = val_dataset.remove_columns(['text'])\n",
    "\n",
    "# Set format for PyTorch\n",
    "train_dataset.set_format('torch')\n",
    "val_dataset.set_format('torch')\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds, average='weighted'),\n",
    "        'recall': recall_score(labels, preds, average='weighted'),\n",
    "        'f1': f1_score(labels, preds, average='weighted')\n",
    "    }\n",
    "\n",
    "# Trainer arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=[]  # disables W&B logging\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:01:25.466679Z",
     "iopub.status.busy": "2025-03-26T13:01:25.466356Z",
     "iopub.status.idle": "2025-03-26T13:31:27.489778Z",
     "shell.execute_reply": "2025-03-26T13:31:27.489067Z",
     "shell.execute_reply.started": "2025-03-26T13:01:25.466652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3024' max='3024' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3024/3024 29:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.834200</td>\n",
       "      <td>0.836931</td>\n",
       "      <td>0.622581</td>\n",
       "      <td>0.623369</td>\n",
       "      <td>0.622581</td>\n",
       "      <td>0.622753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.684800</td>\n",
       "      <td>0.848056</td>\n",
       "      <td>0.632506</td>\n",
       "      <td>0.629310</td>\n",
       "      <td>0.632506</td>\n",
       "      <td>0.630262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.450300</td>\n",
       "      <td>1.015155</td>\n",
       "      <td>0.621340</td>\n",
       "      <td>0.629847</td>\n",
       "      <td>0.621340</td>\n",
       "      <td>0.624087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3024, training_loss=0.7008403053990117, metrics={'train_runtime': 1801.5987, 'train_samples_per_second': 26.839, 'train_steps_per_second': 1.679, 'total_flos': 7454640352042800.0, 'train_loss': 0.7008403053990117, 'epoch': 3.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-26T13:44:06.771961Z",
     "iopub.status.busy": "2025-03-26T13:44:06.771638Z",
     "iopub.status.idle": "2025-03-26T13:44:08.249046Z",
     "shell.execute_reply": "2025-03-26T13:44:08.248369Z",
     "shell.execute_reply.started": "2025-03-26T13:44:06.771931Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model('./hate_speech_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2143201,
     "sourceId": 3566634,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
